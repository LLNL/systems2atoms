{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #3: Heat exchanger design optimization with linear and hyperplane tree surrogates\n",
    "\n",
    "This notebook is part of the Supporting Information of the paper \"Hyperplane Decision Trees as Piecewise Linear Surrogate Models for Chemical Process Design\", by Sunshine et al.\n",
    "\n",
    "Notebook #2 showed details into training surrogate models for PHT tables, using mainly the [hyperplanetree](https://github.com/LLNL/systems2atoms/tree/add-hyperplanetree/systems2atoms/hyperplanetree) Python package. In the present Notebook, we focus in showing the embeding of the surrogates in the optimization problem of a heat exchanger design. \n",
    "\n",
    "Contact the authors of the paper if you have any questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the package from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/cog-imperial/OMLT.git --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/LLNL/systems2atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from systems2atoms.hyperplanetree import LinearTreeRegressor, HyperplaneTreeRegressor, plot_surrogate_2d\n",
    "import torch \n",
    "import sklearn\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lineartree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from systems2atoms.hyperplanetree import HyperplaneTreeDefinition, HyperplaneTreeHybridBigMFormulation, HyperplaneTreeGDPFormulation\n",
    "from omlt.linear_tree import LinearTreeGDPFormulation, LinearTreeDefinition, LinearTreeHybridBigMFormulation\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "torch_device = 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for use in the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(Pa)</th>\n",
       "      <th>H(J/mol)</th>\n",
       "      <th>T(K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>1275.88638</td>\n",
       "      <td>290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.515152e+05</td>\n",
       "      <td>1275.88638</td>\n",
       "      <td>289.942853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.030303e+05</td>\n",
       "      <td>1275.88638</td>\n",
       "      <td>289.885698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.545455e+05</td>\n",
       "      <td>1275.88638</td>\n",
       "      <td>289.828536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.106061e+06</td>\n",
       "      <td>1275.88638</td>\n",
       "      <td>289.771366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.399394e+07</td>\n",
       "      <td>65523.00000</td>\n",
       "      <td>920.211096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2.424545e+07</td>\n",
       "      <td>65523.00000</td>\n",
       "      <td>920.898379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.449697e+07</td>\n",
       "      <td>65523.00000</td>\n",
       "      <td>921.583218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2.474848e+07</td>\n",
       "      <td>65523.00000</td>\n",
       "      <td>922.265623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.500000e+07</td>\n",
       "      <td>65523.00000</td>\n",
       "      <td>922.945606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P(Pa)     H(J/mol)        T(K)\n",
       "0     1.000000e+05   1275.88638  290.000000\n",
       "1     3.515152e+05   1275.88638  289.942853\n",
       "2     6.030303e+05   1275.88638  289.885698\n",
       "3     8.545455e+05   1275.88638  289.828536\n",
       "4     1.106061e+06   1275.88638  289.771366\n",
       "...            ...          ...         ...\n",
       "9995  2.399394e+07  65523.00000  920.211096\n",
       "9996  2.424545e+07  65523.00000  920.898379\n",
       "9997  2.449697e+07  65523.00000  921.583218\n",
       "9998  2.474848e+07  65523.00000  922.265623\n",
       "9999  2.500000e+07  65523.00000  922.945606\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('PHTSV_Table_HMAX_Adjusted.csv', usecols=[0, 1, 2])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features will be the first two columns, pressure and enthalpy data\n",
    "features = torch.tensor(df[['P(Pa)', 'H(J/mol)']].values, dtype=torch.float64)\n",
    "\n",
    "# Response will be the third and last column, of temperature\n",
    "y = torch.tensor(df['T(K)'].values, dtype=torch.float64)\n",
    "\n",
    "features[:, 0] = features[:, 0] / 1e5  # Convert pressure from Pa to bar for consistency with plot in Ammari (20223)\n",
    "features[:, 1] = features[:, 1]  / 1000  # Convert enthalpy from J/mol to kJ/mol \n",
    "\n",
    "pressure = features[:, 0]\n",
    "enthalpy = features[:, 1]\n",
    "temperature = df['T(K)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting train and test splits\n",
    "\n",
    "Here, we use the splitting feature in [scikit-learn](https://scikit-learn.org/stable/). Alternative splitting methodologies can be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [9254 1561 1670 ... 5390  860 7270] (8000 points)\n",
      "Test indices: [6252 4684 1731 ... 7853 1095 6929] (2000 points)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(features))\n",
    "\n",
    "# 20% of the data will be used for test, and 42 is used as the seed for random state, for reproducibility\n",
    "train_features, test_features, train_y, test_y, train_indices, test_indices= train_test_split(features, y, indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Making sure we have shuffled indices and correct splits\n",
    "print(f'Train indices: {train_indices} ({np.size(train_indices)} points)')\n",
    "print(f'Test indices: {test_indices} ({np.size(test_indices)} points)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the different tree surrogates\n",
    "\n",
    "We now train three surrogates. The first (1) is a linear model decision tree. The second (2) is a hyperplane tree model with weight = 2, and the third (3) is a hyperplane tree model with weight = 2. We use these to show how much the hyperparameters influence final results especially regarding training and optimization run times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMDT as used by [Ammari et al](https://www.sciencedirect.com/science/article/pii/S009813542300217X), with the package by [Cerliani](https://github.com/cerlymarco/linear-tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of nodes: 336 | Current number of leaves: 337\n",
      "Model                  # Leaves      Error (MAE)    Training time (s)\n",
      "Hyperplane Tree:       337            0.303          2.99\n"
     ]
    }
   ],
   "source": [
    "model_ltr_ammari_cerliani = lineartree.LinearTreeRegressor(LinearRegression(), \n",
    "                                                           criterion=\"mae\", \n",
    "                                                           min_samples_leaf=0.002, \n",
    "                                                           min_impurity_decrease = -np.inf, \n",
    "                                                           max_depth = 20, \n",
    "                                                           max_bins = 50)\n",
    "\n",
    "t1 = time.time()\n",
    "model_ltr_ammari_cerliani.fit(train_features, train_y)\n",
    "t2 = time.time()\n",
    "\n",
    "y_pred = model_ltr_ammari_cerliani.predict(test_features)\n",
    "linear_error = mean_absolute_error(test_y, y_pred)\n",
    "\n",
    "linear_time = t2 - t1\n",
    "\n",
    "tree_summary = model_ltr_ammari_cerliani.summary()\n",
    "\n",
    "linear_leaves = sum(1 for node_info in tree_summary.values() if 'children' not in node_info)\n",
    "\n",
    "\n",
    "print(f'Model                  # Leaves      Error (MAE)    Training time (s)')\n",
    "print(f'Hyperplane Tree:       {linear_leaves}            {linear_error:.3f}          {linear_time:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperplane tree, with maximum hyperplane weight = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                  # Leaves      Error (MAE)    Training time (s)\n",
      "Hyperplane Tree:       174            0.277          2.61\n"
     ]
    }
   ],
   "source": [
    "model_ht_2 = HyperplaneTreeRegressor(\n",
    "    min_samples_leaf = 0.0043,\n",
    "        max_bins = 50,\n",
    "        max_weight = 2,\n",
    "        disable_tqdm = True,\n",
    "        min_impurity_decrease = -np.inf,\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "model_ht_2.fit(train_features, train_y)\n",
    "t2 = time.time()\n",
    "\n",
    "y_pred_ht = model_ht_2.predict(test_features.to(torch_device)).cpu()\n",
    "\n",
    "hyperplane_error_2 = torch.mean(torch.abs(y_pred_ht - test_y))\n",
    "hyperplane_leaves_2 = len(model_ht_2._leaves)\n",
    "hyperplane_time_2 = t2 - t1\n",
    "\n",
    "print(f'Model                  # Leaves      Error (MAE)    Training time (s)')\n",
    "print(f'Hyperplane Tree:       {hyperplane_leaves_2}            {hyperplane_error_2:.3f}          {hyperplane_time_2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperplane tree, with maximum hyperplane weight = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [9254 1561 1670 ... 5390  860 7270] (8000 points)\n",
      "Test indices: [6252 4684 1731 ... 7853 1095 6929] (2000 points)\n",
      "Model                  # Leaves      Error (MAE)    Training time (s)\n",
      "Hyperplane Tree:       168            0.302          6.94\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('PHTSV_Table_HMAX_Adjusted.csv', usecols=[0, 1, 2])\n",
    "\n",
    "\n",
    "# Features will be the first two columns, pressure and enthalpy data\n",
    "features = torch.tensor(df[['P(Pa)', 'H(J/mol)']].values, dtype=torch.float64)\n",
    "\n",
    "# Response will be the third and last column, of temperature\n",
    "y = torch.tensor(df['T(K)'].values, dtype=torch.float64)\n",
    "\n",
    "features[:, 0] = features[:, 0] / 1e5  # Convert pressure from Pa to bar for consistency with plot in Ammari (20223)\n",
    "features[:, 1] = features[:, 1]  / 1000  # Convert enthalpy from J/mol to kJ/mol \n",
    "\n",
    "pressure = features[:, 0]\n",
    "enthalpy = features[:, 1]\n",
    "temperature = df['T(K)']\n",
    "\n",
    "\n",
    "indices = np.arange(len(features))\n",
    "\n",
    "# 20% of the data will be used for test, and 42 is used as the seed for random state, for reproducibility\n",
    "train_features, test_features, train_y, test_y, train_indices, test_indices= train_test_split(features, y, indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Making sure we have shuffled indices and correct splits\n",
    "print(f'Train indices: {train_indices} ({np.size(train_indices)} points)')\n",
    "print(f'Test indices: {test_indices} ({np.size(test_indices)} points)')\n",
    "\n",
    "\n",
    "\n",
    "model_ht_3 = HyperplaneTreeRegressor(\n",
    "    min_samples_leaf = 0.0043,\n",
    "        max_bins = 50,\n",
    "        max_weight = 3,\n",
    "        disable_tqdm = True,\n",
    "        min_impurity_decrease = -np.inf,\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "model_ht_3.fit(train_features, train_y)\n",
    "t2 = time.time()\n",
    "\n",
    "y_pred_ht = model_ht_3.predict(test_features.to(torch_device)).cpu()\n",
    "\n",
    "hyperplane_error_3 = torch.mean(torch.abs(y_pred_ht - test_y))\n",
    "hyperplane_leaves_3 = len(model_ht_3._leaves)\n",
    "hyperplane_time_3 = t2 - t1\n",
    "\n",
    "print(f'Model                  # Leaves      Error (MAE)    Training time (s)')\n",
    "print(f'Hyperplane Tree:       {hyperplane_leaves_3}            {hyperplane_error_3:.3f}          {hyperplane_time_3:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization framework using the tree surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "from omlt import OmltBlock\n",
    "\n",
    "def create_model(surrogate_def, surrogate_formulation, model, **surrogate_params):\n",
    "    'This function generalizes the creation of a Pyomo model that admits a surrogate model block'\n",
    "\n",
    "    m = pyo.ConcreteModel()\n",
    "\n",
    "    # Define parameters\n",
    "    U = 6341.4\n",
    "    Cp = 1.507\n",
    "    Ks = 20\n",
    "    Ka = 150\n",
    "\n",
    "    # Define variables\n",
    "    m.TsIn = pyo.Var()\n",
    "    m.TsOut = pyo.Var()\n",
    "    m.TpIn = pyo.Var()\n",
    "    m.TpOut = pyo.Var()\n",
    "    m.Fp = pyo.Var(within=pyo.NonNegativeReals)\n",
    "    m.Fs = pyo.Var(within=pyo.NonNegativeReals)\n",
    "    m.A = pyo.Var(within=pyo.NonNegativeReals)\n",
    "    m.PsIn = pyo.Var(within=pyo.NonNegativeReals, bounds=(1, 250))\n",
    "    m.PsOut = pyo.Var(within=pyo.NonNegativeReals, bounds=(1, 250))\n",
    "    m.Q = pyo.Var(within=pyo.NonNegativeReals)\n",
    "    m.HsIn = pyo.Var(within=pyo.NonNegativeReals, bounds=(1.275886, 65.523))\n",
    "    m.HsOut = pyo.Var(within=pyo.NonNegativeReals, bounds=(1.275886, 65.523))\n",
    "    m.LMTD = pyo.Var()\n",
    "    m.dT1 = pyo.Var(bounds=(0.01, None))\n",
    "    m.dT2 = pyo.Var(bounds=(0.01, None))\n",
    "\n",
    "    # Constraints for the model - physical laws and design equations for the HEX\n",
    "    m.heat_transfer = pyo.Constraint(expr=m.Q == U * m.A * m.LMTD)\n",
    "    m.LMTD_chenApp = pyo.Constraint(expr=m.LMTD == (m.dT1 * m.dT2 * (m.dT1 + m.dT2) / 2) ** (1 / 3))\n",
    "    m.dT1_eq = pyo.Constraint(expr=m.dT1 == m.TsOut - m.TpIn)\n",
    "    m.dT2_eq = pyo.Constraint(expr=m.dT2 == m.TsIn - m.TpOut)\n",
    "    m.proc_fluid_thermo = pyo.Constraint(expr=m.Q == m.Fp * Cp * (m.TpOut - m.TpIn))\n",
    "    m.steam_thermo = pyo.Constraint(expr=m.Q == -m.Fs * (m.HsOut - m.HsIn) * 1000 / 18)\n",
    "\n",
    "    # Surrogate block - this is where we embed the surrogate\n",
    "    m.tree_outlet = OmltBlock()\n",
    "    surrogate_instance = surrogate_def(model, **surrogate_params)\n",
    "    formulation_instance = surrogate_formulation(surrogate_instance, 'hull')\n",
    "    m.tree_outlet.build_formulation(formulation_instance)\n",
    "\n",
    "    # Connect surrogate inputs and outputs\n",
    "    m.connect_input_outlet_P = pyo.Constraint(expr=m.PsOut == m.tree_outlet.inputs[0])\n",
    "    m.connect_input_outlet_H = pyo.Constraint(expr=m.HsOut == m.tree_outlet.inputs[1])\n",
    "    m.connect_output_outlet = pyo.Constraint(expr=m.TsOut == m.tree_outlet.outputs[0])\n",
    "\n",
    "    # Objective function - related to minimizing cost od HEX design\n",
    "    m.obj = pyo.Objective(expr=Ks * m.Fs + Ka * m.A)\n",
    "\n",
    "    # Fix variables\n",
    "    m.PsIn.fix(86.047)\n",
    "    m.PsOut.fix(86.047)\n",
    "    m.TsIn.fix(866)\n",
    "    m.TpIn.fix(513.15)\n",
    "    m.TpOut.fix(831)\n",
    "    m.Fp.fix(310 * 3600)\n",
    "    m.HsIn.fix(65.233)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (1.275886, 65.523).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (1.275886, 65.523).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[5]' to a numeric value\n",
      "`0` outside the bounds (3.4724505870716573, 376.9724566432237).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[6]' to a numeric value\n",
      "`0` outside the bounds (5.944901174143315, 503.9449132864475).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[7]' to a numeric value\n",
      "`0` outside the bounds (10.88980234828663, 757.889826572895).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (1.275886, 65.523).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[9]' to a numeric value\n",
      "`0` outside the bounds (2.6481355684297085, 334.6398399623632).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[10]' to a numeric\n",
      "value `0` outside the bounds (3.4724505870716573, 376.9724566432237).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[11]' to a numeric\n",
      "value `0` outside the bounds (5.944901174143315, 503.9449132864475).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[12]' to a numeric\n",
      "value `0` outside the bounds (10.88980234828663, 757.889826572895).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'tree_outlet.scaled_inputs[13]' to a numeric\n",
      "value `0` outside the bounds (15.834703218235017, 1011.834724237442).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "--- Job model.gms Start 04/04/25 19:45:16 41.5.0 2a5a4ddc DEX-DEG x86 64bit/macOS\n",
      "--- Applying:\n",
      "    /Library/Frameworks/GAMS.framework/Versions/41/Resources/gmsprmun.txt\n",
      "--- GAMS Parameters defined\n",
      "    Input /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/model.gms\n",
      "    Output /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/output.lst\n",
      "    ScrDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/225a/\n",
      "    SysDir /Library/Frameworks/GAMS.framework/Versions/41/Resources/\n",
      "    CurDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/\n",
      "    LogOption 3\n",
      "Licensee: Prof. Ignacio E. Grossmann                     G241203|0002AS-GEN\n",
      "          Carnegie Mellon University, Dept. of Chemical Engineering  DCE375\n",
      "          /Users/carolinacolombotedesco/Library/Application Support/GAMS/gamslice.txt\n",
      "          License Admin: Ignacio E. Grossmann,                             \n",
      "          Evaluation license: Not for commercial or production use\n",
      "Processor information: 1 socket(s), 12 core(s), and 12 thread(s) available\n",
      "GAMS 41.5.0   Copyright (C) 1987-2023 GAMS Development. All rights reserved\n",
      "--- Starting compilation\n",
      "--- model.gms(16023) 4 Mb\n",
      "--- Starting execution: elapsed 0:00:00.020\n",
      "--- model.gms(10880) 5 Mb\n",
      "--- Generating MINLP model GAMS_MODEL\n",
      "--- model.gms(10881) 8 Mb\n",
      "--- Reset Solvelink = 2\n",
      "---   3,725 rows  1,364 columns  9,468 non-zeroes\n",
      "---   25 nl-code  6 nl-non-zeroes\n",
      "---   337 discrete-columns\n",
      "--- Range statistics (absolute non-zero finite values)\n",
      "--- RHS       [min, max] : [ 1.000E+00, 5.346E+08] - Zero values observed as well\n",
      "--- Bound     [min, max] : [ 1.000E-02, 3.816E+03] - Zero values observed as well\n",
      "--- Matrix    [min, max] : [ 3.697E-10, 3.816E+03] - Zero values observed as well\n",
      "--- model.gms(10881) 6 Mb\n",
      "--- Executing BARON (Solvelink=2): elapsed 0:00:00.039\n",
      "\n",
      "GAMS/BARON       41.5.0 2a5a4ddc Jan 3, 2023           DEG x86 64bit/macOS    \n",
      "\n",
      "===========================================================================\n",
      " BARON version 22.9.30. Built: OSX-64 Fri Sep 30 09:08:44 EDT 2022\n",
      "\n",
      " BARON is a product of The Optimization Firm.\n",
      " For information on BARON, see https://minlp.com/about-baron\n",
      "XPRESS-MP license initialization failed\n",
      "\n",
      " If you use this software, please cite publications from\n",
      " https://minlp.com/baron-publications, such as: \n",
      "\n",
      " Kilinc, M. and N. V. Sahinidis, Exploiting integrality in the global\n",
      " optimization of mixed-integer nonlinear programming problems in BARON,\n",
      " Optimization Methods and Software, 33, 540-562, 2018.\n",
      "===========================================================================\n",
      " This BARON run may utilize the following subsolver(s)\n",
      " For LP/MIP/QP: CLP/CBC, ILOG CPLEX                             \n",
      " For NLP: MINOS, SNOPT, External NLP, IPOPT, FILTERSQP\n",
      "===========================================================================\n",
      " Doing local search\n",
      " Solving bounding LP\n",
      " Starting multi-start local search\n",
      " Preprocessing found feasible solution with value 0.487601E+07\n",
      " Done with local search\n",
      "===========================================================================\n",
      "  Iteration    Open nodes         Time (s)    Lower bound      Upper bound\n",
      "*         1             1             0.39     0.469746E+07     0.476420E+07\n",
      "*         1+            0             0.47     0.476246E+07     0.476294E+07\n",
      "          1             0             0.48     0.476246E+07     0.476294E+07\n",
      "\n",
      " Calculating duals\n",
      "\n",
      "                         *** Normal completion ***            \n",
      "\n",
      " Wall clock time:                     0.66\n",
      " Total CPU time used:                 0.55\n",
      "\n",
      " Total no. of BaR iterations:       1\n",
      " Best solution found at node:       1\n",
      " Max. no. of nodes in memory:       1\n",
      " \n",
      " All done\n",
      "===========================================================================\n",
      "\n",
      "Solution      = 4762935.83499793  found at node 1\n",
      "Best possible = 4762459.58904\n",
      "Absolute gap  = 476.245957929641  optca = 1E-9\n",
      "Relative gap  = 9.99900007953494E-5  optcr = 0.0001\n",
      "\n",
      "--- Reading solution for model GAMS_MODEL\n",
      "--- Executing after solve: elapsed 0:00:00.852\n",
      "--- model.gms(10884) 6 Mb\n",
      "--- model.gms(16023) 6 Mb\n",
      "--- Putfile results /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/results.dat\n",
      "--- Putfile statresults /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmplkav2hvv/resultsstat.dat\n",
      "*** Status: Normal completion\n",
      "--- Job model.gms Stop 04/04/25 19:45:17 elapsed 0:00:00.867\n",
      "--- Job model.gms Start 04/04/25 19:45:17 41.5.0 2a5a4ddc DEX-DEG x86 64bit/macOS\n",
      "--- Applying:\n",
      "    /Library/Frameworks/GAMS.framework/Versions/41/Resources/gmsprmun.txt\n",
      "--- GAMS Parameters defined\n",
      "    Input /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/model.gms\n",
      "    Output /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/output.lst\n",
      "    ScrDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/225a/\n",
      "    SysDir /Library/Frameworks/GAMS.framework/Versions/41/Resources/\n",
      "    CurDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/\n",
      "    LogOption 3\n",
      "Licensee: Prof. Ignacio E. Grossmann                     G241203|0002AS-GEN\n",
      "          Carnegie Mellon University, Dept. of Chemical Engineering  DCE375\n",
      "          /Users/carolinacolombotedesco/Library/Application Support/GAMS/gamslice.txt\n",
      "          License Admin: Ignacio E. Grossmann,                             \n",
      "          Evaluation license: Not for commercial or production use\n",
      "Processor information: 1 socket(s), 12 core(s), and 12 thread(s) available\n",
      "GAMS 41.5.0   Copyright (C) 1987-2023 GAMS Development. All rights reserved\n",
      "--- Starting compilation\n",
      "--- model.gms(25708) 6 Mb\n",
      "--- Starting execution: elapsed 0:00:00.142\n",
      "--- model.gms(17758) 6 Mb\n",
      "--- Generating MINLP model GAMS_MODEL\n",
      "--- model.gms(10232) 9 Mb\n",
      "--- model.gms(17759) 10 Mb\n",
      "--- Reset Solvelink = 2\n",
      "---   6,126 rows  1,768 columns  14,336 non-zeroes\n",
      "---   25 nl-code  6 nl-non-zeroes\n",
      "---   174 discrete-columns\n",
      "--- Range statistics (absolute non-zero finite values)\n",
      "--- RHS       [min, max] : [ 1.000E+00, 5.346E+08] - Zero values observed as well\n",
      "--- Bound     [min, max] : [ 1.000E-02, 1.011E+04] - Zero values observed as well\n",
      "--- Matrix    [min, max] : [ 3.631E-05, 1.011E+04] - Zero values observed as well\n",
      "--- model.gms(17759) 8 Mb\n",
      "--- Executing BARON (Solvelink=2): elapsed 0:00:00.263\n",
      "\n",
      "GAMS/BARON       41.5.0 2a5a4ddc Jan 3, 2023           DEG x86 64bit/macOS    \n",
      "\n",
      "===========================================================================\n",
      " BARON version 22.9.30. Built: OSX-64 Fri Sep 30 09:08:44 EDT 2022\n",
      "\n",
      " BARON is a product of The Optimization Firm.\n",
      " For information on BARON, see https://minlp.com/about-baron\n",
      "XPRESS-MP license initialization failed\n",
      "\n",
      " If you use this software, please cite publications from\n",
      " https://minlp.com/baron-publications, such as: \n",
      "\n",
      " Kilinc, M. and N. V. Sahinidis, Exploiting integrality in the global\n",
      " optimization of mixed-integer nonlinear programming problems in BARON,\n",
      " Optimization Methods and Software, 33, 540-562, 2018.\n",
      "===========================================================================\n",
      " This BARON run may utilize the following subsolver(s)\n",
      " For LP/MIP/QP: CLP/CBC, ILOG CPLEX                             \n",
      " For NLP: MINOS, SNOPT, External NLP, IPOPT, FILTERSQP\n",
      "===========================================================================\n",
      " Doing local search\n",
      " Solving bounding LP\n",
      " Starting multi-start local search\n",
      " Preprocessing found feasible solution with value 0.556653E+07\n",
      " Done with local search\n",
      "===========================================================================\n",
      "  Iteration    Open nodes         Time (s)    Lower bound      Upper bound\n",
      "*         1             1             0.70     0.363624E+07     0.487597E+07\n",
      "*         1+            1             0.80     0.423331E+07     0.487548E+07\n",
      "*         1+            1             0.84     0.423331E+07     0.487499E+07\n",
      "*         1             1             0.91     0.466865E+07     0.476443E+07\n",
      "          1             0             0.96     0.476396E+07     0.476443E+07\n",
      "\n",
      " Calculating duals\n",
      "\n",
      "                         *** Normal completion ***            \n",
      "\n",
      " Wall clock time:                     1.38\n",
      " Total CPU time used:                 1.04\n",
      "\n",
      " Total no. of BaR iterations:       1\n",
      " Best solution found at node:       1\n",
      " Max. no. of nodes in memory:       1\n",
      " \n",
      " All done\n",
      "===========================================================================\n",
      "\n",
      "Solution      = 4764431.96984227  found at node 1\n",
      "Best possible = 4763955.57428\n",
      "Absolute gap  = 476.395562265068  optca = 1E-9\n",
      "Relative gap  = 9.9990002015044E-5  optcr = 0.0001\n",
      "\n",
      "--- Reading solution for model GAMS_MODEL\n",
      "--- Executing after solve: elapsed 0:00:02.045\n",
      "--- model.gms(17762) 8 Mb\n",
      "--- model.gms(25708) 8 Mb\n",
      "--- Putfile results /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/results.dat\n",
      "--- Putfile statresults /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpprafq6q2/resultsstat.dat\n",
      "*** Status: Normal completion\n",
      "--- Job model.gms Stop 04/04/25 19:45:20 elapsed 0:00:02.067\n",
      "--- Job model.gms Start 04/04/25 19:45:20 41.5.0 2a5a4ddc DEX-DEG x86 64bit/macOS\n",
      "--- Applying:\n",
      "    /Library/Frameworks/GAMS.framework/Versions/41/Resources/gmsprmun.txt\n",
      "--- GAMS Parameters defined\n",
      "    Input /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/model.gms\n",
      "    Output /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/output.lst\n",
      "    ScrDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/225a/\n",
      "    SysDir /Library/Frameworks/GAMS.framework/Versions/41/Resources/\n",
      "    CurDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/\n",
      "    LogOption 3\n",
      "Licensee: Prof. Ignacio E. Grossmann                     G241203|0002AS-GEN\n",
      "          Carnegie Mellon University, Dept. of Chemical Engineering  DCE375\n",
      "          /Users/carolinacolombotedesco/Library/Application Support/GAMS/gamslice.txt\n",
      "          License Admin: Ignacio E. Grossmann,                             \n",
      "          Evaluation license: Not for commercial or production use\n",
      "Processor information: 1 socket(s), 12 core(s), and 12 thread(s) available\n",
      "GAMS 41.5.0   Copyright (C) 1987-2023 GAMS Development. All rights reserved\n",
      "--- Starting compilation\n",
      "--- model.gms(41746) 8 Mb\n",
      "--- Starting execution: elapsed 0:00:00.045\n",
      "--- model.gms(28996) 9 Mb\n",
      "--- Generating MINLP model GAMS_MODEL\n",
      "--- model.gms(28997) 13 Mb\n",
      "--- Reset Solvelink = 2\n",
      "---   9,966 rows  2,728 columns  22,952 non-zeroes\n",
      "---   25 nl-code  6 nl-non-zeroes\n",
      "---   168 discrete-columns\n",
      "--- Range statistics (absolute non-zero finite values)\n",
      "--- RHS       [min, max] : [ 1.000E+00, 5.346E+08] - Zero values observed as well\n",
      "--- Bound     [min, max] : [ 1.000E-02, 1.236E+04] - Zero values observed as well\n",
      "--- Matrix    [min, max] : [ 7.822E-08, 1.236E+04] - Zero values observed as well\n",
      "--- model.gms(28997) 11 Mb\n",
      "--- Executing BARON (Solvelink=2): elapsed 0:00:00.086\n",
      "\n",
      "GAMS/BARON       41.5.0 2a5a4ddc Jan 3, 2023           DEG x86 64bit/macOS    \n",
      "\n",
      "===========================================================================\n",
      " BARON version 22.9.30. Built: OSX-64 Fri Sep 30 09:08:44 EDT 2022\n",
      "\n",
      " BARON is a product of The Optimization Firm.\n",
      " For information on BARON, see https://minlp.com/about-baron\n",
      "XPRESS-MP license initialization failed\n",
      "\n",
      " If you use this software, please cite publications from\n",
      " https://minlp.com/baron-publications, such as: \n",
      "\n",
      " Kilinc, M. and N. V. Sahinidis, Exploiting integrality in the global\n",
      " optimization of mixed-integer nonlinear programming problems in BARON,\n",
      " Optimization Methods and Software, 33, 540-562, 2018.\n",
      "===========================================================================\n",
      " This BARON run may utilize the following subsolver(s)\n",
      " For LP/MIP/QP: CLP/CBC, ILOG CPLEX                             \n",
      " For NLP: MINOS, SNOPT, External NLP, IPOPT, FILTERSQP\n",
      "===========================================================================\n",
      " Doing local search\n",
      " Solving bounding LP\n",
      " Starting multi-start local search\n",
      " Done with local search\n",
      "===========================================================================\n",
      "  Iteration    Open nodes         Time (s)    Lower bound      Upper bound\n",
      "*         1+            1             3.44     0.432282E+07     0.110463E+08\n",
      "*         1+            1             3.55     0.432282E+07     0.110452E+08\n",
      "*         1+            1             3.75     0.462710E+07     0.110441E+08\n",
      "*         1+            1             3.82     0.462710E+07     0.110430E+08\n",
      "*         1+            1             4.03     0.462723E+07     0.110419E+08\n",
      "*         1+            1             4.10     0.462723E+07     0.110408E+08\n",
      "          1             1             4.19     0.462723E+07     0.110408E+08\n",
      "*         6             5             4.26     0.466115E+07     0.486669E+07\n",
      "*         7+            5             4.49     0.466115E+07     0.486620E+07\n",
      "*         7+            5             4.56     0.466115E+07     0.486572E+07\n",
      "*         7+            5             4.62     0.466115E+07     0.486523E+07\n",
      "*         7+            5             4.71     0.466115E+07     0.486474E+07\n",
      "*         7+            5             4.76     0.466115E+07     0.486426E+07\n",
      "*         9             6             4.84     0.466115E+07     0.486343E+07\n",
      "*        11             2             4.90     0.466115E+07     0.476439E+07\n",
      "         13             0             5.03     0.476392E+07     0.476439E+07\n",
      "\n",
      " Calculating duals\n",
      "\n",
      "                         *** Normal completion ***            \n",
      "\n",
      " Wall clock time:                     5.15\n",
      " Total CPU time used:                 5.13\n",
      "\n",
      " Total no. of BaR iterations:      13\n",
      " Best solution found at node:      11\n",
      " Max. no. of nodes in memory:       6\n",
      " \n",
      " All done\n",
      "===========================================================================\n",
      "\n",
      "Solution      = 4764391.79767707  found at node 11\n",
      "Best possible = 4763915.40614\n",
      "Absolute gap  = 476.391537074  optca = 1E-9\n",
      "Relative gap  = 9.99900002569623E-5  optcr = 0.0001\n",
      "\n",
      "--- Reading solution for model GAMS_MODEL\n",
      "--- Executing after solve: elapsed 0:00:05.764\n",
      "--- model.gms(29000) 11 Mb\n",
      "--- model.gms(41746) 11 Mb\n",
      "--- Putfile results /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/results.dat\n",
      "--- Putfile statresults /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmpteaqqbn2/resultsstat.dat\n",
      "*** Status: Normal completion\n",
      "--- Job model.gms Stop 04/04/25 19:45:26 elapsed 0:00:05.798\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "m1 = create_model(\n",
    "    surrogate_def=LinearTreeDefinition,\n",
    "    surrogate_formulation=LinearTreeGDPFormulation,\n",
    "    model=model_ltr_ammari_cerliani,\n",
    "    unscaled_input_bounds={0: (1, 250), 1: (1.275886, 65.523)}\n",
    ")\n",
    "\n",
    "m2 = create_model(\n",
    "    surrogate_def=HyperplaneTreeDefinition,\n",
    "    surrogate_formulation=HyperplaneTreeGDPFormulation,\n",
    "    model=model_ht_2,\n",
    "    input_bounds_matrix=torch.tensor([[1, 250], [1.275886, 65.523]], dtype=torch.float64)\n",
    ")\n",
    "\n",
    "m3 = create_model(\n",
    "    surrogate_def=HyperplaneTreeDefinition,\n",
    "    surrogate_formulation=HyperplaneTreeGDPFormulation,\n",
    "    model=model_ht_3,\n",
    "    input_bounds_matrix=torch.tensor([[1, 250], [1.275886, 65.523]], dtype=torch.float64)\n",
    ")\n",
    "\n",
    "# Use the global solver BARON - here we used the GAMS interface \n",
    "solver = pyo.SolverFactory(\"gams:baron\")\n",
    "\n",
    "\n",
    "# Solve m1 and measure time\n",
    "start_time_m1 = time.time()\n",
    "results1 = solver.solve(m1, tee=True)\n",
    "end_time_m1 = time.time()\n",
    "time_m1 = end_time_m1 - start_time_m1\n",
    "\n",
    "# Solve m2 and measure time\n",
    "start_time_m2 = time.time()\n",
    "results2 = solver.solve(m2, tee=True)\n",
    "end_time_m2 = time.time()\n",
    "time_m2 = end_time_m2 - start_time_m2\n",
    "\n",
    "\n",
    "# Solve m3 and measure time\n",
    "start_time_m3 = time.time()\n",
    "results3 = solver.solve(m3, tee=True)\n",
    "end_time_m3 = time.time()\n",
    "time_m3 = end_time_m3 - start_time_m3\n",
    "\n",
    "m3_obj = pyo.value(m3.obj)\n",
    "m3_Fs_kg_s = m3.Fs.value / 3600\n",
    "m3_area = m3.A.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original formulation results as mentioned in Ammari (2023)\n",
    "original_obj = 4.78e6  #Value for the objective\n",
    "original_Fs = 60.31   # Value for steam flow (kg/s)\n",
    "original_A = 2924     # Value for heat exchanger area (m2)\n",
    "\n",
    "m1_obj = m1.obj.expr()\n",
    "m1_Fs = m1.Fs.value / 3600  # Convert to kg/s\n",
    "m1_A = m1.A.value\n",
    "\n",
    "m2_obj = m2.obj.expr()\n",
    "m2_Fs = m2.Fs.value / 3600  # Convert to kg/s\n",
    "m2_A = m2.A.value\n",
    "\n",
    "m3_obj = m3.obj.expr()\n",
    "m3_Fs = m3.Fs.value / 3600  # Convert to kg/s\n",
    "m3_A = m3.A.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results comparison only considering tree surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Original formulation</th>\n",
       "      <th>For linear tree surrogate</th>\n",
       "      <th>For hyperplane tree surrogate (W = 3)</th>\n",
       "      <th>For hyperplane tree surrogate (W = 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Objective Value ($)</td>\n",
       "      <td>4.78e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steam Flow (kg/s)</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.08</td>\n",
       "      <td>60.09</td>\n",
       "      <td>60.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heat Exchanger Area (m2)</td>\n",
       "      <td>2924</td>\n",
       "      <td>2915</td>\n",
       "      <td>2919</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run time (s)</td>\n",
       "      <td>-</td>\n",
       "      <td>1.33</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># of leaves</td>\n",
       "      <td>-</td>\n",
       "      <td>337</td>\n",
       "      <td>168</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAE (K)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training time (s)</td>\n",
       "      <td>-</td>\n",
       "      <td>2.99</td>\n",
       "      <td>6.94</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BARON Memory usage (MB)</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Original formulation For linear tree surrogate  \\\n",
       "0       Objective Value ($)             4.78e+06                  4.76e+06   \n",
       "1         Steam Flow (kg/s)                60.31                     60.08   \n",
       "2  Heat Exchanger Area (m2)                 2924                      2915   \n",
       "3              Run time (s)                    -                      1.33   \n",
       "4               # of leaves                    -                       337   \n",
       "5                   MAE (K)                    -                      0.30   \n",
       "6         Training time (s)                    -                      2.99   \n",
       "7   BARON Memory usage (MB)                    -                         6   \n",
       "\n",
       "  For hyperplane tree surrogate (W = 3) For hyperplane tree surrogate (W = 2)  \n",
       "0                              4.76e+06                              4.76e+06  \n",
       "1                                 60.09                                 60.09  \n",
       "2                                  2919                                  2921  \n",
       "3                                  6.12                                  2.33  \n",
       "4                                   168                                   174  \n",
       "5                                  0.30                                  0.28  \n",
       "6                                  6.94                                  2.61  \n",
       "7                                     8                                    11  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Objective Value ($)\", \n",
    "        \"Steam Flow (kg/s)\", \n",
    "        \"Heat Exchanger Area (m2)\", \n",
    "        \"Run time (s)\", \n",
    "        \"# of leaves\", \n",
    "        \"MAE (K)\",\n",
    "        \"Training time (s)\",\n",
    "        \"BARON Memory usage (MB)\"\n",
    "    ],\n",
    "    \"Original formulation\": [\n",
    "        f\"{original_obj:.2e}\", \n",
    "        f\"{original_Fs:.2f}\", \n",
    "        f\"{original_A:.0f}\", \n",
    "        \"-\", \n",
    "        \"-\", \n",
    "        \"-\", \n",
    "        \"-\",\n",
    "        \"-\",\n",
    "    ],\n",
    "    \"For linear tree surrogate\": [\n",
    "        f\"{m1_obj:.2e}\", \n",
    "        f\"{m1_Fs:.2f}\", \n",
    "        f\"{m1_A:.0f}\", \n",
    "        f\"{time_m1:.2f}\", \n",
    "        f\"{linear_leaves}\", \n",
    "        f\"{linear_error:.2f}\",\n",
    "        f\"{linear_time:.2f}\",\n",
    "        6 \n",
    "    ],\n",
    "    \"For hyperplane tree surrogate (W = 3)\": [\n",
    "        f\"{m3_obj:.2e}\", \n",
    "        f\"{m3_Fs:.2f}\", \n",
    "        f\"{m3_A:.0f}\", \n",
    "        f\"{time_m3:.2f}\", \n",
    "        f\"{hyperplane_leaves_3}\", \n",
    "        f\"{hyperplane_error_3:.2f}\",\n",
    "        f\"{hyperplane_time_3:.2f}\",\n",
    "        8 \n",
    "    ],\n",
    "        \"For hyperplane tree surrogate (W = 2)\": [\n",
    "        f\"{m2_obj:.2e}\", \n",
    "        f\"{m2_Fs:.2f}\", \n",
    "        f\"{m2_A:.0f}\", \n",
    "        f\"{time_m2:.2f}\", \n",
    "        f\"{hyperplane_leaves_2}\", \n",
    "        f\"{hyperplane_error_2:.2f}\",\n",
    "        f\"{hyperplane_time_2:.2f}\",\n",
    "        11 \n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network (ANN) as surrogate\n",
    "\n",
    "With the ReLU activation function. Therefore, the surrogate is also piecewise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "Using scikit-learn for grid search of ideal hyperparameters, to achieve a low MAE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 336 candidates, totalling 1008 fits\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   5.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   5.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   6.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.6s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-06, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   6.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   5.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=1e-05, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   4.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   6.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   5.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   5.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   4.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   4.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   4.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   6.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   5.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   5.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   3.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150,), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.1s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(150, 75), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.5s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0005, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0003, max_iter=500, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=128, early_stopping=True, hidden_layer_sizes=(200, 100, 50, 25), learning_rate_init=0.0001, max_iter=500, solver=adam; total time=   2.9s\n",
      "Best Parameters:\n",
      "{'activation': 'relu', 'alpha': 1e-06, 'batch_size': 32, 'early_stopping': True, 'hidden_layer_sizes': (200, 100, 50, 25), 'learning_rate_init': 0.0003, 'max_iter': 500, 'solver': 'adam'}\n",
      "MAE of best model: 1.027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare data \n",
    "X_train = train_features.numpy()\n",
    "y_train = train_y.numpy().flatten()\n",
    "X_test = test_features.numpy()\n",
    "y_test = test_y.numpy().flatten()\n",
    "\n",
    "# Scale features and target\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (100,), (150,), (100, 50), (150, 75),\n",
    "        (128, 64, 32), (200, 100, 50), (200, 100, 50, 25)\n",
    "    ],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [1e-6, 1e-5, 1e-4, 1e-3],  \n",
    "    'learning_rate_init': [0.001, 0.0005, 0.0003, 0.0001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'max_iter': [500], \n",
    "    'early_stopping': [True],\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Results\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluate best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_scaled = best_model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE of best model: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the ANN with PyTorch and optimal hyperparameters\n",
    "\n",
    "Using PyTorch for compatibility with OMLT, but using the hyperparametes found previously to achieve a low MAE. \n",
    "\n",
    "Further exploration can lead to improvement of the model, which could alter the results obtained here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model               Error (MAE)    Training time (s)\n",
      "Neural Network:       1.916          56.35\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tempfile\n",
    "import onnx\n",
    "from omlt.io import write_onnx_model_with_bounds\n",
    "\n",
    "# Raw data\n",
    "train_features_raw = train_features.float()\n",
    "test_features_raw = test_features.float()\n",
    "train_y_raw = train_y.float().unsqueeze(1)\n",
    "test_y_raw = test_y.float().unsqueeze(1)\n",
    "\n",
    "# Neural Network Definition \n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dims=(200, 100, 50, 25), output_dim=1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], hidden_dims[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[2], hidden_dims[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[3], output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = FeedforwardNN()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_features_raw, train_y_raw)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Training \n",
    "start = time.time()\n",
    "for epoch in range(400):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "end = time.time()\n",
    "time_nn = end - start\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(test_features_raw.to(device)).cpu().numpy().flatten()\n",
    "    targets = test_y_raw.numpy().flatten()\n",
    "    mae_nn = np.mean(np.abs(preds - targets))\n",
    "\n",
    "\n",
    "# Export to ONNX\n",
    "dummy_input = torch.randn(1, 2)\n",
    "input_bounds = [(1, 250), (1.275886, 65.523)]  # raw units: bar, kJ/mol\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as f:\n",
    "    torch.onnx.export(\n",
    "        model, dummy_input, f.name,\n",
    "        input_names=[\"input\"], output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "    )\n",
    "    onnx_model = onnx.load(f.name)\n",
    "    write_onnx_model_with_bounds(f.name, onnx_model, input_bounds)\n",
    "    onnx_path = f.name\n",
    "\n",
    "\n",
    "print(f'Model               Error (MAE)    Training time (s)')\n",
    "print(f'Neural Network:       {mae_nn:.3f}          {time_nn:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the optimization problem with the embeded ANN surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (W1002): Setting Var 'nn_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'nn_outlet.scaled_inputs[0]' to a numeric value\n",
      "`0` outside the bounds (1.0, 250.0).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "WARNING (W1002): Setting Var 'nn_outlet.scaled_inputs[1]' to a numeric value\n",
      "`0` outside the bounds (1.275886, 65.523).\n",
      "    See also https://pyomo.readthedocs.io/en/stable/errors.html#w1002\n",
      "--- Job model.gms Start 04/04/25 19:48:56 41.5.0 2a5a4ddc DEX-DEG x86 64bit/macOS\n",
      "--- Applying:\n",
      "    /Library/Frameworks/GAMS.framework/Versions/41/Resources/gmsprmun.txt\n",
      "--- GAMS Parameters defined\n",
      "    Input /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/model.gms\n",
      "    Output /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/output.lst\n",
      "    ScrDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/225a/\n",
      "    SysDir /Library/Frameworks/GAMS.framework/Versions/41/Resources/\n",
      "    CurDir /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/\n",
      "    LogOption 3\n",
      "Licensee: Prof. Ignacio E. Grossmann                     G241203|0002AS-GEN\n",
      "          Carnegie Mellon University, Dept. of Chemical Engineering  DCE375\n",
      "          /Users/carolinacolombotedesco/Library/Application Support/GAMS/gamslice.txt\n",
      "          License Admin: Ignacio E. Grossmann,                             \n",
      "          Evaluation license: Not for commercial or production use\n",
      "Processor information: 1 socket(s), 12 core(s), and 12 thread(s) available\n",
      "GAMS 41.5.0   Copyright (C) 1987-2023 GAMS Development. All rights reserved\n",
      "--- Starting compilation\n",
      "--- model.gms(9990) 4 Mb\n",
      "--- Starting execution: elapsed 0:00:00.031\n",
      "--- model.gms(6898) 5 Mb\n",
      "--- Generating MINLP model GAMS_MODEL\n",
      "--- model.gms(6899) 9 Mb\n",
      "--- Reset Solvelink = 2\n",
      "---   1,893 rows  1,145 columns  30,087 non-zeroes\n",
      "---   25 nl-code  6 nl-non-zeroes\n",
      "---   375 discrete-columns\n",
      "--- Range statistics (absolute non-zero finite values)\n",
      "--- RHS       [min, max] : [ 8.460E-04, 5.346E+08] - Zero values observed as well\n",
      "--- Bound     [min, max] : [ 1.000E-02, 1.592E+04] - Zero values observed as well\n",
      "--- Matrix    [min, max] : [ 1.563E-06, 6.341E+05] - Zero values observed as well\n",
      "--- model.gms(6899) 7 Mb\n",
      "--- Executing BARON (Solvelink=2): elapsed 0:00:00.054\n",
      "\n",
      "GAMS/BARON       41.5.0 2a5a4ddc Jan 3, 2023           DEG x86 64bit/macOS    \n",
      "\n",
      "===========================================================================\n",
      " BARON version 22.9.30. Built: OSX-64 Fri Sep 30 09:08:44 EDT 2022\n",
      "\n",
      " BARON is a product of The Optimization Firm.\n",
      " For information on BARON, see https://minlp.com/about-baron\n",
      "\n",
      " If you use this software, please cite publications from\n",
      " https://minlp.com/baron-publications, such as: \n",
      "\n",
      " Kilinc, M. and N. V. Sahinidis, Exploiting integrality in the global\n",
      " optimization of mixed-integer nonlinear programming problems in BARON,\n",
      " Optimization Methods and Software, 33, 540-562, 2018.\n",
      "===========================================================================\n",
      " This BARON run may utilize the following subsolver(s)\n",
      " For LP/MIP/QP: CLP/CBC, ILOG CPLEX                             \n",
      " For NLP: MINOS, SNOPT, External NLP, IPOPT, FILTERSQP\n",
      "===========================================================================\n",
      " Doing local search\n",
      " Solving bounding LP\n",
      " Starting multi-start local search\n",
      " Done with local search\n",
      "===========================================================================\n",
      "  Iteration    Open nodes         Time (s)    Lower bound      Upper bound\n",
      "          1+            1            34.56     0.309390E+07     0.100000E+52\n",
      "          1+            1            64.55     0.309390E+07     0.100000E+52\n",
      "          1+            1            94.53     0.309390E+07     0.100000E+52\n",
      "          1+            1           124.48     0.309390E+07     0.100000E+52\n",
      "          1             1           135.23     0.309390E+07     0.100000E+52\n",
      "          2+            2           165.24     0.309390E+07     0.100000E+52\n",
      "          2+            2           195.21     0.309390E+07     0.100000E+52\n",
      "          2+            2           225.22     0.309390E+07     0.100000E+52\n",
      "          3+            3           255.16     0.309390E+07     0.100000E+52\n",
      "          3+            3           285.02     0.309390E+07     0.100000E+52\n",
      "          4+            4           314.83     0.309390E+07     0.100000E+52\n",
      "          4+            4           344.91     0.309390E+07     0.100000E+52\n",
      "          6+            4           374.74     0.309390E+07     0.100000E+52\n",
      "          6+            4           404.68     0.309390E+07     0.100000E+52\n",
      "          6+            4           434.60     0.309390E+07     0.100000E+52\n",
      "          7+            5           464.58     0.309390E+07     0.100000E+52\n",
      "          7+            5           494.44     0.309390E+07     0.100000E+52\n",
      "          8+            4           524.41     0.309390E+07     0.100000E+52\n",
      "          8+            4           554.29     0.309390E+07     0.100000E+52\n",
      "          8+            4           583.93     0.309390E+07     0.100000E+52\n",
      "*         8             4           601.77     0.309390E+07     0.478404E+07\n",
      "         10+            4           631.72     0.309390E+07     0.478404E+07\n",
      "         14+            4           661.12     0.309390E+07     0.478404E+07\n",
      "         14+            4           690.80     0.309390E+07     0.478404E+07\n",
      "         14+            4           720.67     0.309390E+07     0.478404E+07\n",
      "         19+            4           750.52     0.309390E+07     0.478404E+07\n",
      "         19+            4           780.47     0.309390E+07     0.478404E+07\n",
      "         19+            4           810.27     0.309390E+07     0.478404E+07\n",
      "         19+            4           840.24     0.309390E+07     0.478404E+07\n",
      "         20+            5           869.98     0.309390E+07     0.478404E+07\n",
      "         20+            5           899.51     0.309390E+07     0.478404E+07\n",
      "*        20             5           925.22     0.309390E+07     0.475773E+07\n",
      "         21+            6           955.10     0.309390E+07     0.475773E+07\n",
      "         28+            8           984.88     0.309390E+07     0.475773E+07\n",
      "         30+            8          1014.85     0.309390E+07     0.475773E+07\n",
      "         36+           10          1044.81     0.309390E+07     0.475773E+07\n",
      "         36+           10          1074.77     0.309390E+07     0.475773E+07\n",
      "         36+           10          1103.76     0.309390E+07     0.475773E+07\n",
      "         36+           10          1133.73     0.309390E+07     0.475773E+07\n",
      "         36+           10          1163.67     0.309390E+07     0.475773E+07\n",
      "         38+           12          1193.70     0.309390E+07     0.475773E+07\n",
      "         38+           12          1223.77     0.309390E+07     0.475773E+07\n",
      "         38+           12          1254.00     0.309390E+07     0.475773E+07\n",
      "         38+           12          1284.01     0.309390E+07     0.475773E+07\n",
      "         61+           13          1313.91     0.309390E+07     0.475773E+07\n",
      "         73+           10          1343.68     0.309390E+07     0.475773E+07\n",
      "         73+           10          1373.70     0.309390E+07     0.475773E+07\n",
      "         73+           10          1403.73     0.309390E+07     0.475773E+07\n",
      "         73+           10          1433.65     0.309390E+07     0.475773E+07\n",
      "         75+           11          1463.52     0.309390E+07     0.475773E+07\n",
      "         75+           11          1493.68     0.309390E+07     0.475773E+07\n",
      "         75+           11          1523.63     0.309390E+07     0.475773E+07\n",
      "         75+           11          1553.62     0.309390E+07     0.475773E+07\n",
      "         75+           11          1583.61     0.309390E+07     0.475773E+07\n",
      "         80+           10          1613.60     0.314782E+07     0.475773E+07\n",
      "         81+           10          1643.76     0.314782E+07     0.475773E+07\n",
      "         81+           10          1673.75     0.314782E+07     0.475773E+07\n",
      "         81+           10          1703.70     0.314782E+07     0.475773E+07\n",
      "         83+           10          1733.70     0.314782E+07     0.475773E+07\n",
      "         83+           10          1763.63     0.314782E+07     0.475773E+07\n",
      "         83+           10          1793.66     0.314782E+07     0.475773E+07\n",
      "         83+           10          1823.67     0.314782E+07     0.475773E+07\n",
      "         84+           10          1853.66     0.317109E+07     0.475773E+07\n",
      "         84+           10          1883.61     0.317109E+07     0.475773E+07\n",
      "         84+           10          1913.63     0.317109E+07     0.475773E+07\n",
      "         86+           11          1943.60     0.317109E+07     0.475773E+07\n",
      "         86+           11          1973.72     0.317109E+07     0.475773E+07\n",
      "         86+           11          2003.67     0.317109E+07     0.475773E+07\n",
      "         87+           11          2033.21     0.317109E+07     0.475773E+07\n",
      "         87+           11          2062.87     0.317109E+07     0.475773E+07\n",
      "         88+           10          2092.83     0.317400E+07     0.475773E+07\n",
      "         89+           10          2122.76     0.317400E+07     0.475773E+07\n",
      "         89+           10          2152.68     0.317400E+07     0.475773E+07\n",
      "         91+           10          2182.63     0.317400E+07     0.475773E+07\n",
      "         92+            9          2212.49     0.324004E+07     0.475773E+07\n",
      "         92+            9          2242.51     0.324004E+07     0.475773E+07\n",
      "         93+            9          2272.51     0.324004E+07     0.475773E+07\n",
      "         94+           10          2302.49     0.326553E+07     0.475773E+07\n",
      "         97+            9          2332.54     0.326553E+07     0.475773E+07\n",
      "         97+            9          2362.53     0.326553E+07     0.475773E+07\n",
      "         98+           10          2392.49     0.326553E+07     0.475773E+07\n",
      "         98+           10          2422.35     0.326553E+07     0.475773E+07\n",
      "         98+           10          2452.37     0.326553E+07     0.475773E+07\n",
      "        100+           10          2482.20     0.327574E+07     0.475773E+07\n",
      "        100+           10          2512.17     0.327574E+07     0.475773E+07\n",
      "        100+           10          2542.09     0.327574E+07     0.475773E+07\n",
      "        104+            9          2572.04     0.331490E+07     0.475773E+07\n",
      "        123+           11          2601.96     0.331490E+07     0.475773E+07\n",
      "        156+           14          2632.00     0.331490E+07     0.475773E+07\n",
      "        188+           10          2661.80     0.331490E+07     0.475773E+07\n",
      "        213+           11          2691.70     0.331490E+07     0.475773E+07\n",
      "        252+           15          2721.51     0.333618E+07     0.475773E+07\n",
      "        320            13          2752.01     0.344303E+07     0.475773E+07\n",
      "        381            16          2782.03     0.346550E+07     0.475773E+07\n",
      "        486+           24          2811.92     0.351248E+07     0.475773E+07\n",
      "        609+           18          2841.86     0.363388E+07     0.475773E+07\n",
      "        609+           18          2871.79     0.363388E+07     0.475773E+07\n",
      "        609+           18          2901.68     0.363388E+07     0.475773E+07\n",
      "        751+           20          2931.61     0.391429E+07     0.475773E+07\n",
      "        904+           27          2961.56     0.399752E+07     0.475773E+07\n",
      "        976+           33          2991.64     0.402446E+07     0.475773E+07\n",
      "       1008+           35          3021.62     0.402446E+07     0.475773E+07\n",
      "       1069+           33          3051.64     0.402446E+07     0.475773E+07\n",
      "       1193+           33          3081.41     0.402446E+07     0.475773E+07\n",
      "       1330+           37          3111.31     0.411889E+07     0.475773E+07\n",
      "       1475+           40          3141.24     0.421392E+07     0.475773E+07\n",
      "       1637+           38          3171.13     0.421392E+07     0.475773E+07\n",
      "       1837            43          3201.02     0.422456E+07     0.475773E+07\n",
      "       1902+           48          3231.01     0.422456E+07     0.475773E+07\n",
      "       1955            50          3261.06     0.422456E+07     0.475773E+07\n",
      "       2058+           52          3290.95     0.422456E+07     0.475773E+07\n",
      "*      2089            51          3309.22     0.422456E+07     0.475446E+07\n",
      "       2189            54          3338.44     0.422456E+07     0.475446E+07\n",
      "       2297+           55          3368.30     0.422456E+07     0.475446E+07\n",
      "       2422+           64          3398.26     0.422456E+07     0.475446E+07\n",
      "       2558+           68          3428.09     0.422456E+07     0.475446E+07\n",
      "       2720+           65          3458.71     0.422456E+07     0.475446E+07\n",
      "       2837+           69          3488.63     0.422456E+07     0.475446E+07\n",
      "       2983+           74          3518.62     0.422456E+07     0.475446E+07\n",
      "       3175+           83          3548.57     0.422456E+07     0.475446E+07\n",
      "       3437+           81          3578.55     0.423323E+07     0.475446E+07\n",
      "       3710            80          3608.38     0.423323E+07     0.475446E+07\n",
      "       3841+           85          3638.43     0.424547E+07     0.475446E+07\n",
      "       3986+           94          3668.45     0.424547E+07     0.475446E+07\n",
      "       4152+           98          3698.45     0.424547E+07     0.475446E+07\n",
      "       4306+           95          3728.40     0.425121E+07     0.475446E+07\n",
      "       4455+          102          3758.36     0.425121E+07     0.475446E+07\n",
      "       4654+          108          3788.11     0.425121E+07     0.475446E+07\n",
      "       4842+          115          3818.08     0.425121E+07     0.475446E+07\n",
      "       4993+          114          3847.83     0.425483E+07     0.475446E+07\n",
      "       5242+          122          3877.81     0.425483E+07     0.475446E+07\n",
      "       5406+          115          3907.78     0.426753E+07     0.475446E+07\n",
      "       5505+          116          3937.78     0.426753E+07     0.475446E+07\n",
      "       5692+          113          3967.69     0.427267E+07     0.475446E+07\n",
      "       5812+          114          3997.61     0.427267E+07     0.475446E+07\n",
      "*      5842           113          4005.77     0.427267E+07     0.475446E+07\n",
      "       6033+          120          4035.74     0.427709E+07     0.475446E+07\n",
      "       6293+          122          4065.65     0.429734E+07     0.475446E+07\n",
      "       6468           123          4095.58     0.430397E+07     0.475446E+07\n",
      "       6653           125          4125.52     0.431544E+07     0.475446E+07\n",
      "       6871+          129          4155.41     0.431870E+07     0.475446E+07\n",
      "       7131+          136          4185.42     0.431870E+07     0.475446E+07\n",
      "       7327           131          4215.85     0.432102E+07     0.475446E+07\n",
      "       7526           137          4245.79     0.432734E+07     0.475446E+07\n",
      "       7772           139          4275.74     0.432734E+07     0.475446E+07\n",
      "       7988+          141          4305.83     0.433974E+07     0.475446E+07\n",
      "       8250+          143          4335.67     0.434868E+07     0.475446E+07\n",
      "       8483           139          4365.60     0.435314E+07     0.475446E+07\n",
      "       8752+          139          4394.68     0.436831E+07     0.475446E+07\n",
      "       8966+          138          4424.63     0.437359E+07     0.475446E+07\n",
      "       9271+          134          4454.53     0.441292E+07     0.475446E+07\n",
      "       9499+          140          4484.31     0.441822E+07     0.475446E+07\n",
      "       9770           138          4514.05     0.441831E+07     0.475446E+07\n",
      "       9969+          131          4543.97     0.443014E+07     0.475446E+07\n",
      "      10171           134          4573.90     0.443221E+07     0.475446E+07\n",
      "      10454+          126          4603.88     0.444819E+07     0.475446E+07\n",
      "      10724           124          4633.91     0.445461E+07     0.475446E+07\n",
      "      10981           125          4663.76     0.447231E+07     0.475446E+07\n",
      "      11290           128          4693.76     0.448176E+07     0.475446E+07\n",
      "      11537+          127          4723.56     0.448668E+07     0.475446E+07\n",
      "      11834           127          4753.49     0.449987E+07     0.475446E+07\n",
      "      12099           121          4783.46     0.450489E+07     0.475446E+07\n",
      "      12390           114          4814.86     0.452329E+07     0.475446E+07\n",
      "      12634+          111          4844.87     0.454301E+07     0.475446E+07\n",
      "      12880+           98          4875.15     0.455782E+07     0.475446E+07\n",
      "      13162+           87          4905.16     0.457419E+07     0.475446E+07\n",
      "      13329+           81          4935.12     0.458009E+07     0.475446E+07\n",
      "      13504            82          4965.08     0.461259E+07     0.475446E+07\n",
      "      13780+           63          4995.08     0.463486E+07     0.475446E+07\n",
      "      14022            53          5025.09     0.467097E+07     0.475446E+07\n",
      "      14292+           37          5054.99     0.471854E+07     0.475446E+07\n",
      "      14509             0          5075.37     0.475398E+07     0.475446E+07\n",
      "\n",
      " Calculating duals\n",
      "\n",
      "                         *** Normal completion ***            \n",
      "\n",
      " Wall clock time:                  5096.13\n",
      " Total CPU time used:              5075.49\n",
      "\n",
      " Total no. of BaR iterations:   14509\n",
      " Best solution found at node:   13950\n",
      " Max. no. of nodes in memory:     149\n",
      " \n",
      " All done\n",
      "===========================================================================\n",
      "\n",
      "Solution      = 4754458.08811734  found at node 13950\n",
      "Best possible = 4753982.68985\n",
      "Absolute gap  = 475.398267341778  optca = 1E-9\n",
      "Relative gap  = 9.99900006543174E-5  optcr = 0.0001\n",
      "\n",
      "--- Reading solution for model GAMS_MODEL\n",
      "--- Executing after solve: elapsed 1:24:56.418\n",
      "--- model.gms(6902) 7 Mb\n",
      "--- model.gms(9990) 7 Mb\n",
      "--- Putfile results /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/results.dat\n",
      "--- Putfile statresults /private/var/folders/ly/14n5x27j4x58m15svpw3z2zm0000gn/T/tmp6ue53n1j/resultsstat.dat\n",
      "*** Status: Normal completion\n",
      "--- Job model.gms Stop 04/04/25 21:13:53 elapsed 1:24:56.429\n"
     ]
    }
   ],
   "source": [
    "from omlt.io import load_onnx_neural_network_with_bounds\n",
    "from omlt.neuralnet import FullSpaceNNFormulation\n",
    "\n",
    "m = pyo.ConcreteModel()\n",
    "\n",
    "# Define parameters\n",
    "U = 6341.4\n",
    "Cp = 1.507\n",
    "Ks = 20\n",
    "Ka = 150\n",
    "\n",
    "# Define variables\n",
    "m.TsIn = pyo.Var()\n",
    "m.TsOut = pyo.Var()\n",
    "m.TpIn = pyo.Var()\n",
    "m.TpOut = pyo.Var()\n",
    "m.Fp = pyo.Var(within=pyo.NonNegativeReals)\n",
    "m.Fs = pyo.Var(within=pyo.NonNegativeReals)\n",
    "m.A = pyo.Var(within=pyo.NonNegativeReals)\n",
    "m.PsIn = pyo.Var(within=pyo.NonNegativeReals, bounds=(1, 250), initialize=100)\n",
    "m.PsOut = pyo.Var(within=pyo.NonNegativeReals, bounds=(1, 250), initialize=100)\n",
    "m.Q = pyo.Var(bounds=(0, 1e6), initialize=1e5)\n",
    "m.HsIn = pyo.Var(within=pyo.NonNegativeReals, bounds=(1.275886, 65.523))\n",
    "m.HsOut = pyo.Var(within=pyo.NonNegativeReals, bounds=(1.275886, 65.523))\n",
    "m.LMTD = pyo.Var(bounds=(1e-3, 1000), initialize=10)\n",
    "m.dT1 = pyo.Var(bounds=(0.01, None))\n",
    "m.dT2 = pyo.Var(bounds=(0.01, None))\n",
    "\n",
    "m.TsIn = pyo.Var(bounds=(300, 1000), initialize=500)\n",
    "m.TsOut = pyo.Var(bounds=(300, 1000), initialize=500)\n",
    "\n",
    "m.TpIn = pyo.Var(bounds=(300, 1000), initialize=500)\n",
    "m.TpOut = pyo.Var(bounds=(300, 1000), initialize=500)\n",
    "\n",
    "m.Fp = pyo.Var(bounds=(0, 1e5), initialize=1000)\n",
    "m.Fs = pyo.Var(bounds=(0, 1e5), initialize=5000)\n",
    "\n",
    "m.A = pyo.Var(bounds=(0.01, 1e4), initialize=100)  # Heat exchanger area\n",
    "\n",
    "m.PsIn = pyo.Var(bounds=(1, 250), initialize=100)\n",
    "m.PsOut = pyo.Var(bounds=(1, 250), initialize=100)\n",
    "\n",
    "\n",
    "# Constraints for the model - physical laws and design equations for the HEX\n",
    "m.heat_transfer = pyo.Constraint(expr=m.Q == U * m.A * m.LMTD)\n",
    "m.LMTD_chenApp = pyo.Constraint(expr=m.LMTD == (m.dT1 * m.dT2 * (m.dT1 + m.dT2) / 2) ** (1 / 3))\n",
    "m.dT1_eq = pyo.Constraint(expr=m.dT1 == m.TsOut - m.TpIn)\n",
    "m.dT2_eq = pyo.Constraint(expr=m.dT2 == m.TsIn - m.TpOut)\n",
    "m.proc_fluid_thermo = pyo.Constraint(expr=m.Q == m.Fp * Cp * (m.TpOut - m.TpIn))\n",
    "m.steam_thermo = pyo.Constraint(expr=m.Q == -m.Fs * (m.HsOut - m.HsIn) * 1000 / 18)\n",
    "\n",
    "# NN surrogate block - this is where we embed the surrogate\n",
    "nn_definition = load_onnx_neural_network_with_bounds(onnx_path)\n",
    "m.nn_outlet = OmltBlock()\n",
    "formulation = FullSpaceNNFormulation(nn_definition)\n",
    "m.nn_outlet.build_formulation(formulation)\n",
    "\n",
    "# Connect surrogate inputs and outputs\n",
    "m.connect_input_outlet_P = pyo.Constraint(expr=m.PsOut == m.nn_outlet.inputs[0])\n",
    "m.connect_input_outlet_H = pyo.Constraint(expr=m.HsOut == m.nn_outlet.inputs[1])\n",
    "m.connect_output_outlet = pyo.Constraint(expr=m.TsOut == m.nn_outlet.outputs[0])\n",
    "\n",
    "# Bounds on TsOut - it's important to add the bounds not to get extrapolated values from the NN\n",
    "m.TsOut.setlb(288.0)\n",
    "m.TsOut.setub(930.0)\n",
    "\n",
    "# Objective function - related to minimizing cost od HEX design\n",
    "m.obj = pyo.Objective(expr=Ks * m.Fs + Ka * m.A)\n",
    "\n",
    "# Fix variables\n",
    "m.PsIn.fix(86.047)\n",
    "m.TsIn.fix(866)\n",
    "m.TpIn.fix(513.15)\n",
    "m.TpOut.fix(831)\n",
    "m.Fp.fix(310 * 3600)\n",
    "m.HsIn.fix(65.233)\n",
    "\n",
    "m.PsOut.set_value(100.0)\n",
    "m.HsOut.set_value(30.0)\n",
    "m.A.set_value(100.0)\n",
    "m.Fs.set_value(5000.0)\n",
    "m.TsOut.set_value(500.0)\n",
    "\n",
    "\n",
    "# Solve\n",
    "solver = pyo.SolverFactory(\"gams:baron\")\n",
    "\n",
    "start_time_m = time.time()\n",
    "results = solver.solve(m, tee=True)\n",
    "end_time_m = time.time()\n",
    "\n",
    "time_m = end_time_m - start_time_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results comparison considering the neural network and tree surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_obj = m.obj.expr()\n",
    "m_Fs = m.Fs.value / 3600  # Convert to kg/s\n",
    "m_A = m.A.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Original formulation</th>\n",
       "      <th>For linear tree surrogate</th>\n",
       "      <th>For hyperplane tree surrogate (W = 3)</th>\n",
       "      <th>For hyperplane tree surrogate (W = 2)</th>\n",
       "      <th>For the neural network surrogate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Objective Value ($)</td>\n",
       "      <td>4.78e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "      <td>4.76e+06</td>\n",
       "      <td>4.75e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steam Flow (kg/s)</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.08</td>\n",
       "      <td>60.09</td>\n",
       "      <td>60.09</td>\n",
       "      <td>60.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heat Exchanger Area (m2)</td>\n",
       "      <td>2924</td>\n",
       "      <td>2915</td>\n",
       "      <td>2919</td>\n",
       "      <td>2921</td>\n",
       "      <td>2888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run time (s)</td>\n",
       "      <td>-</td>\n",
       "      <td>1.33</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.33</td>\n",
       "      <td>5096.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># of leaves</td>\n",
       "      <td>-</td>\n",
       "      <td>337</td>\n",
       "      <td>168</td>\n",
       "      <td>174</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAE (K)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training time (s)</td>\n",
       "      <td>-</td>\n",
       "      <td>2.99</td>\n",
       "      <td>6.94</td>\n",
       "      <td>2.61</td>\n",
       "      <td>56.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BARON Memory usage (MB)</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric Original formulation For linear tree surrogate  \\\n",
       "0       Objective Value ($)             4.78e+06                  4.76e+06   \n",
       "1         Steam Flow (kg/s)                60.31                     60.08   \n",
       "2  Heat Exchanger Area (m2)                 2924                      2915   \n",
       "3              Run time (s)                    -                      1.33   \n",
       "4               # of leaves                    -                       337   \n",
       "5                   MAE (K)                    -                      0.30   \n",
       "6         Training time (s)                    -                      2.99   \n",
       "7   BARON Memory usage (MB)                    -                         6   \n",
       "\n",
       "  For hyperplane tree surrogate (W = 3) For hyperplane tree surrogate (W = 2)  \\\n",
       "0                              4.76e+06                              4.76e+06   \n",
       "1                                 60.09                                 60.09   \n",
       "2                                  2919                                  2921   \n",
       "3                                  6.12                                  2.33   \n",
       "4                                   168                                   174   \n",
       "5                                  0.30                                  0.28   \n",
       "6                                  6.94                                  2.61   \n",
       "7                                     8                                    11   \n",
       "\n",
       "  For the neural network surrogate  \n",
       "0                         4.75e+06  \n",
       "1                            60.02  \n",
       "2                             2888  \n",
       "3                          5096.89  \n",
       "4                                -  \n",
       "5                             1.92  \n",
       "6                            56.35  \n",
       "7                                7  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Objective Value ($)\", \n",
    "        \"Steam Flow (kg/s)\", \n",
    "        \"Heat Exchanger Area (m2)\", \n",
    "        \"Run time (s)\", \n",
    "        \"# of leaves\", \n",
    "        \"MAE (K)\",\n",
    "        \"Training time (s)\",\n",
    "        \"BARON Memory usage (MB)\"\n",
    "    ],\n",
    "    \"Original formulation\": [\n",
    "        f\"{original_obj:.2e}\", \n",
    "        f\"{original_Fs:.2f}\", \n",
    "        f\"{original_A:.0f}\", \n",
    "        \"-\", \n",
    "        \"-\", \n",
    "        \"-\", \n",
    "        \"-\",\n",
    "        \"-\",\n",
    "    ],\n",
    "    \"For linear tree surrogate\": [\n",
    "        f\"{m1_obj:.2e}\", \n",
    "        f\"{m1_Fs:.2f}\", \n",
    "        f\"{m1_A:.0f}\", \n",
    "        f\"{time_m1:.2f}\", \n",
    "        f\"{linear_leaves}\", \n",
    "        f\"{linear_error:.2f}\",\n",
    "        f\"{linear_time:.2f}\",\n",
    "        6 \n",
    "    ],\n",
    "    \"For hyperplane tree surrogate (W = 3)\": [\n",
    "        f\"{m3_obj:.2e}\", \n",
    "        f\"{m3_Fs:.2f}\", \n",
    "        f\"{m3_A:.0f}\", \n",
    "        f\"{time_m3:.2f}\", \n",
    "        f\"{hyperplane_leaves_3}\", \n",
    "        f\"{hyperplane_error_3:.2f}\",\n",
    "        f\"{hyperplane_time_3:.2f}\",\n",
    "        8 \n",
    "    ],\n",
    "        \"For hyperplane tree surrogate (W = 2)\": [\n",
    "        f\"{m2_obj:.2e}\", \n",
    "        f\"{m2_Fs:.2f}\", \n",
    "        f\"{m2_A:.0f}\", \n",
    "        f\"{time_m2:.2f}\", \n",
    "        f\"{hyperplane_leaves_2}\", \n",
    "        f\"{hyperplane_error_2:.2f}\",\n",
    "        f\"{hyperplane_time_2:.2f}\",\n",
    "        11 \n",
    "    ],\n",
    "        \"For the neural network surrogate\": [\n",
    "        f\"{m_obj:.2e}\", \n",
    "        f\"{m_Fs:.2f}\", \n",
    "        f\"{m_A:.0f}\", \n",
    "        f\"{time_m:.2f}\", \n",
    "        f\"{'-'}\", \n",
    "        f\"{mae_nn:.2f}\",\n",
    "        f\"{time_nn:.2f}\",\n",
    "        7\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further discussion about the results in this table can be seen in the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
